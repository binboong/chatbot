import os
import sys
import chromadb
import google.generativeai as genai
from dotenv import load_dotenv
from chromadb.utils import embedding_functions
from onnx_embedder import get_embedder  # import ONNX embedder báº¡n Ä‘Ã£ viáº¿t

# Äáº£m báº£o UTF-8 encoding cho console
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')
if sys.stderr.encoding != 'utf-8':
    sys.stderr.reconfigure(encoding='utf-8')

# Load API key tá»« .env
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    print("âŒ GOOGLE_API_KEY khÃ´ng Ä‘Æ°á»£c tÃ¬m tháº¥y trong .env file!")
    sys.exit(1)

genai.configure(api_key=api_key)
llm = genai.GenerativeModel("gemini-2.5-flash-lite")
print("âœ… Khá»Ÿi táº¡o Gemini thÃ nh cÃ´ng")

# Custom embedding function (dÃ¹ng ONNXEmbedder)
class LocalEmbeddingFunction(embedding_functions.EmbeddingFunction):
    def __init__(self, model_path="./models"):
        self.embedder = get_embedder(model_path)

    def __call__(self, input):
        if isinstance(input, str):
            input = [input]
        embeddings = self.embedder(input)
        return embeddings.tolist() if hasattr(embeddings, "tolist") else embeddings


# Khá»Ÿi táº¡o ChromaDB client
try:
    client = chromadb.PersistentClient(path="./vector_db")
    embedding_fn = LocalEmbeddingFunction("./models")
    collection = client.get_or_create_collection(
        name="knowledge_base",
        embedding_function=embedding_fn
    )
    print(f"âœ… Káº¿t ná»‘i ChromaDB thÃ nh cÃ´ng. Collection: {collection.name}")
except Exception as e:
    print(f"âŒ Lá»—i káº¿t ná»‘i ChromaDB: {e}")
    print("ğŸ’¡ HÃ£y cháº¡y db_setup.py hoáº·c ingest.py trÆ°á»›c")
    sys.exit(1)

def chat(user_query: str, max_context_length=10000):
    if not user_query or not user_query.strip():
        return "Vui lÃ²ng nháº­p cÃ¢u há»i."
    
    try:
        print("ğŸ” Äang tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan...")
        results = collection.query(
            query_texts=[user_query],
            n_results=5,
            include=["documents", "metadatas"]
        )
        
        context = ""
        sources = []
        if results["documents"] and results["documents"][0]:
            docs = results["documents"][0]
            for i, doc in enumerate(docs):
                if doc and doc.strip():
                    context += doc + "\n\n"
                    if (results.get("metadatas") and 
                        results["metadatas"][0] and 
                        len(results["metadatas"][0]) > i and
                        results["metadatas"][0][i]):
                        source = results["metadatas"][0][i].get("filename", "Unknown")
                        if source not in sources:
                            sources.append(source)
            
            if len(context) > max_context_length:
                context = context[:max_context_length] + "..."
            
            if sources:
                context += f"\n\nğŸ“š Nguá»“n: {', '.join(sources)}"
        
        if not context.strip():
            context = "KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u."

        prompt = f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh vÃ  há»¯u Ã­ch. HÃ£y tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p.

THÃ”NG TIN TÃŒM ÄÆ¯á»¢C:
{context}

CÃ‚U Há»I NGÆ¯á»œI DÃ™NG: {user_query}

HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
1. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t hoáº·c tiáº¿ng Anh tÃ¹y thuá»™c vÃ o ngÃ´n ngá»¯ cÃ¢u há»i
2. Dá»±a chá»§ yáº¿u vÃ o thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p
3. Náº¿u khÃ´ng cÃ³ thÃ´ng tin liÃªn quan, hÃ£y thÃ nh tháº­t nÃ³i ráº±ng khÃ´ng tÃ¬m tháº¥y
4. Tráº£ lá»i ngáº¯n gá»n, rÃµ rÃ ng vÃ  há»¯u Ã­ch
"""

        print("ğŸ¤– Äang táº¡o pháº£n há»“i...")
        response = llm.generate_content(prompt)
        
        if response and response.text:
            return response.text.strip()
        else:
            return "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ táº¡o pháº£n há»“i lÃºc nÃ y. Vui lÃ²ng thá»­ láº¡i."
    
    except Exception as e:
        print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½: {e}")
        return f"ÄÃ£ xáº£y ra lá»—i: {str(e)}. Vui lÃ²ng thá»­ láº¡i."

def main():
    print("=" * 50)
    print("ğŸ¤– CHATBOT THÃ”NG MINH")
    print("ğŸ’¡ Nháº­p 'exit', 'quit' hoáº·c 'thoat' Ä‘á»ƒ káº¿t thÃºc")
    print("ğŸ’¡ Nháº­p 'help' Ä‘á»ƒ xem hÆ°á»›ng dáº«n")
    print("=" * 50)
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ Báº¡n: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ["exit", "quit", "thoat", "bye"]:
                print("ğŸ‘‹ Táº¡m biá»‡t! Háº¹n gáº·p láº¡i!")
                break
            
            if user_input.lower() in ["help", "giup", "hÆ°á»›ng dáº«n"]:
                print("""
ğŸ“‹ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG:
â€¢ Äáº·t cÃ¢u há»i vá» ná»™i dung trong dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c ingest
â€¢ Há»— trá»£ tiáº¿ng Viá»‡t vÃ  tiáº¿ng Anh
â€¢ Nháº­p 'exit' Ä‘á»ƒ thoÃ¡t
â€¢ Nháº­p 'help' Ä‘á»ƒ xem hÆ°á»›ng dáº«n nÃ y
                """)
                continue
            
            response = chat(user_input)
            print(f"\nğŸ¤– Chatbot: {response}")
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ÄÃ£ dá»«ng chatbot. Táº¡m biá»‡t!")
            break
        except EOFError:
            print("\n\nğŸ‘‹ Táº¡m biá»‡t!")
            break
        except Exception as e:
            print(f"\nâŒ Lá»—i khÃ´ng mong muá»‘n: {e}")
            print("ğŸ”„ Vui lÃ²ng thá»­ láº¡i...")

if __name__ == "__main__":
    main()
